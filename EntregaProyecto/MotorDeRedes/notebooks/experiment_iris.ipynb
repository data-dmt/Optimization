{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1b9f2fb",
   "metadata": {},
   "source": [
    "## Dataset Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e04c3b7",
   "metadata": {},
   "source": [
    "#### 1. Carga de datos y librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60c6e96",
   "metadata": {},
   "source": [
    "Este cuaderno demuestra el flujo completo sobre el conjunto Iris usando únicamente numpy, pandas y matplotlib, además de las clases propias en src/.\n",
    "\n",
    "En esta sección:\n",
    "- Añadimos la ruta al paquete local src/.\n",
    "- Cargamos Iris.csv desde ../data/.\n",
    "- Separamos atributos y etiquetas; convertimos etiquetas de texto a índices 0..K-1 y luego a one-hot.\n",
    "- Estandarizamos las columnas de X (media 0, desviación 1) para estabilizar el entrenamiento.\n",
    "\n",
    "La estandarización aquí se calcula sobre todo el conjunto para simplificar el ejemplo de Iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc37c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src.NeuralNetwork import NeuralNetwork\n",
    "from src.OptimizerAdam import OptimizerAdam\n",
    "from src.Trainer import Trainer\n",
    "from src.Losses import categorical_cross_entropy\n",
    "from src.HyperparameterTuner import HyperparameterTuner\n",
    "\n",
    "df = pd.read_csv(\"../data/Iris.csv\")\n",
    "X = df.iloc[:, 1:-1].values\n",
    "y_labels = df.iloc[:, -1].values\n",
    "unique_classes = np.unique(y_labels)\n",
    "y = np.array([np.where(unique_classes == label)[0][0] for label in y_labels])\n",
    "Y = np.zeros((y.size, len(unique_classes)))\n",
    "Y[np.arange(y.size), y] = 1\n",
    "\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028b083e",
   "metadata": {},
   "source": [
    "####  2. División en Train/Test/Val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491d84d2",
   "metadata": {},
   "source": [
    "Se realiza una partición con semilla fija para reproducibilidad:\n",
    "- 80 % entrenamiento, 10 % validación, 10 % prueba.\n",
    "- Se barajan los índices y se trocean por tamaños.\n",
    "\n",
    "El objetivo es disponer de un conjunto de validación para monitorizar early stopping y evitar sobreajuste; y un conjunto test totalmente ciego para el resultado final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bbce25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados: 150 muestras, 4 atributos, 3 clases\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "indices = np.random.permutation(X.shape[0])\n",
    "\n",
    "train_size = int(0.8 * X.shape[0])\n",
    "val_size = int(0.1 * X.shape[0])\n",
    "\n",
    "train_idx = indices[:train_size]\n",
    "val_idx = indices[train_size:train_size + val_size]\n",
    "test_idx = indices[train_size + val_size:]\n",
    "\n",
    "X_train, Y_train = X[train_idx], Y[train_idx]\n",
    "X_val, Y_val = X[val_idx], Y[val_idx]\n",
    "X_test, Y_test = X[test_idx], Y[test_idx]\n",
    "\n",
    "print(f\"Datos cargados: {X.shape[0]} muestras, {X.shape[1]} atributos, {Y.shape[1]} clases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9d75e4",
   "metadata": {},
   "source": [
    "#### 3. Búsqueda de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a576788",
   "metadata": {},
   "source": [
    "Usamos HyperparameterTuner para explorar combinaciones razonables de:\n",
    "- Tasa de aprendizaje (lr), batch size, regularización L2, capas ocultas, activación, parámetros de Adam y dropout.\n",
    "- Métricas de selección: mejor val_acc y, a empate, menor val_loss.\n",
    "- Paciencia de early stopping para cortar entrenamientos que dejan de mejorar.\n",
    "\n",
    "Este grid es acotado y pequeño para Iris, con fines demostrativos. El cuaderno imprime un Top-5 de configuraciones por validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "454f0aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [1/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [2/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [3/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [4/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [5/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [6/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [7/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [8/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [9/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [10/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [11/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [12/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [13/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [14/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [15/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [16/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [17/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [18/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [19/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [20/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [21/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [22/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [23/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [24/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [25/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [26/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [27/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [28/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [29/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [30/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [31/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [32/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [33/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [34/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [35/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [36/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [37/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [38/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [39/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [40/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [41/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [42/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [43/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [44/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [45/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [46/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [47/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [48/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [49/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [50/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [51/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [52/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [53/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [54/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [55/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [56/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [57/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [58/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [59/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [60/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [61/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [62/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [63/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [64/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [65/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [66/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [67/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [68/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [69/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [70/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [71/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [72/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [73/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [74/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [75/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [76/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [77/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [78/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [79/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [80/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [81/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [82/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [83/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [84/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [85/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [86/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [87/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [88/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [89/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [90/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [91/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [92/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [93/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [94/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [95/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [96/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [97/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [98/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [99/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [100/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [101/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [102/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [103/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [104/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [105/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [106/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [107/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [108/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [109/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [110/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [111/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [112/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [113/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [114/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [115/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [116/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [117/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [118/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [119/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [120/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [121/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [122/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [123/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [124/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [125/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [126/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [127/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [128/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [129/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [130/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [131/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [132/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [133/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [134/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [135/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [136/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [137/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [138/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [139/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [140/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [141/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [142/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [143/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [144/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "\n",
      " [145/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [146/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [147/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [148/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [149/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [150/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [151/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [152/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [153/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [154/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [155/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [156/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [157/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [158/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [159/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [160/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [161/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [162/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [163/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [164/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [165/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [166/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [167/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [168/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [169/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [170/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [171/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [172/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [173/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [174/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [175/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [176/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [177/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [178/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [179/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [180/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [181/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [182/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [183/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [184/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [185/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [186/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [187/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [188/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [189/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [190/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [191/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [192/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [193/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [194/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [195/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [196/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [197/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [198/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [199/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [200/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [201/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [202/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [203/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [204/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [205/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [206/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [207/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [208/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [209/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [210/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [211/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [212/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [213/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [214/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [215/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [216/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [217/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [218/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [219/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [220/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [221/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [222/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [223/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [224/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [225/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [226/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [227/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [228/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [229/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [230/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [231/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [232/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [233/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [234/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [235/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [236/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [237/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [238/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [239/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [240/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [241/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [242/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [243/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [244/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [245/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [246/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [247/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [248/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [249/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [250/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [251/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [252/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [253/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [254/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [255/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [256/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [257/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [258/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [259/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [260/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [261/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [262/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [263/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [264/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [265/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [266/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [267/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [268/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [269/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [270/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [271/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [272/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [273/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [274/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [275/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [276/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [277/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [278/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [279/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [280/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [281/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [282/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [283/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [284/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [285/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "\n",
      " [286/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [287/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [288/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [289/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [290/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [291/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [292/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [293/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [294/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [295/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [296/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [297/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [298/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [299/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [300/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [301/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [302/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [303/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [304/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [305/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [306/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [307/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [308/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [309/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [310/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [311/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [312/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [313/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [314/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [315/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [316/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [317/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [318/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [319/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [320/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [321/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [322/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [323/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [324/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [325/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [326/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [327/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [328/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [329/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [330/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [331/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [332/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [333/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [334/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [335/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [336/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [337/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [338/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [339/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [340/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [341/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [342/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [343/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [344/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [345/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [346/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [347/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [348/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [349/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [350/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [351/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [352/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [353/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [354/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [355/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [356/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [357/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [358/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [359/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [360/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [361/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [362/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [363/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [364/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [365/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [366/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [367/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [368/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [369/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [370/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [371/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [372/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [373/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [374/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [375/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [376/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [377/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [378/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [379/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [380/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [381/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [382/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [383/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [384/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [385/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [386/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [387/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [388/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [389/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [390/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [391/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [392/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [393/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [394/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [395/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [396/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [397/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [398/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [399/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [400/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [401/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [402/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [403/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [404/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [405/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [406/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [407/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [408/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [409/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [410/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [411/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [412/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [413/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [414/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [415/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [416/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [417/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [418/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [419/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [420/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [421/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [422/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [423/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [424/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [425/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [426/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [427/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [428/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [429/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "\n",
      " [430/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [431/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [432/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [433/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [434/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [435/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [436/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [437/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [438/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [439/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [440/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [441/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [442/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [443/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [444/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [445/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [446/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [447/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [448/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [449/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [450/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [451/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [452/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [453/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [454/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [455/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [456/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [457/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [458/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [459/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [460/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [461/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [462/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [463/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [464/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [465/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [466/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [467/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [468/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [469/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [470/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [471/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [472/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [473/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [474/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [475/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [476/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [477/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [478/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [479/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [480/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [481/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [482/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [483/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [484/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [485/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [486/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [487/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [488/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [489/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [490/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [491/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [492/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [493/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [494/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [495/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [496/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [497/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [498/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [499/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [500/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [501/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [502/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [503/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [504/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [505/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [506/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [507/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [508/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [509/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [510/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [511/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [512/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [513/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [514/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [515/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [516/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [517/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [518/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [519/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [520/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [521/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [522/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [523/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [524/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [525/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [526/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [527/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [528/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [529/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Decaimiento del learning rate: nuevo lr = 0.077378\n",
      "\n",
      " [530/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Decaimiento del learning rate: nuevo lr = 0.077378\n",
      "\n",
      " [531/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Decaimiento del learning rate: nuevo lr = 0.077378\n",
      "\n",
      " [532/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [533/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [534/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [535/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [536/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [537/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [538/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [539/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [540/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [541/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [542/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [543/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [544/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [545/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [546/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [547/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [548/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [549/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [550/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [551/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [552/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [553/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [554/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [555/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [556/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [557/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [558/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [559/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [560/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [561/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [562/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [563/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [564/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [565/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Decaimiento del learning rate: nuevo lr = 0.077378\n",
      "\n",
      " [566/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Decaimiento del learning rate: nuevo lr = 0.077378\n",
      "\n",
      " [567/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Decaimiento del learning rate: nuevo lr = 0.077378\n",
      "\n",
      " [568/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [569/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [570/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [571/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [572/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [573/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [574/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [575/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [576/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [1/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [2/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [3/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [4/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [5/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [6/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [7/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [8/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [9/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [10/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [11/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [12/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [13/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [14/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [15/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [16/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [17/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [18/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [19/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [20/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [21/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [22/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [23/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [24/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [25/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [26/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [27/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [28/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [29/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [30/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [31/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [32/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [33/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [34/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [35/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [36/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [37/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [38/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [39/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [40/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [41/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [42/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [43/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [44/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [45/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [46/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [47/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [48/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [49/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [50/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [51/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [52/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [53/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [54/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [55/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [56/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [57/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [58/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [59/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [60/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [61/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [62/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [63/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [64/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [65/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [66/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [67/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [68/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [69/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [70/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [71/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [72/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [73/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [74/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [75/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [76/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [77/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [78/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [79/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [80/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [81/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [82/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [83/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [84/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [85/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [86/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [87/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [88/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [89/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [90/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [91/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [92/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [93/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [94/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [95/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [96/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [97/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [98/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [99/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [100/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [101/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [102/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [103/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [104/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [105/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [106/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [107/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [108/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [109/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [110/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [111/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [112/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [113/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [114/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [115/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [116/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [117/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [118/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [119/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [120/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [121/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [122/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [123/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [124/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [125/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [126/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [127/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [128/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [129/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [130/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [131/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [132/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [133/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [134/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [135/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [136/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [137/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [138/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [139/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [140/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [141/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [142/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [143/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [144/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "\n",
      " [145/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [146/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [147/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [148/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [149/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [150/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [151/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [152/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [153/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [154/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [155/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [156/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [157/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [158/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [159/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [160/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [161/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [162/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [163/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [164/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [165/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [166/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [167/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [168/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [169/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [170/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [171/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [172/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [173/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [174/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [175/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [176/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [177/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [178/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [179/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [180/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [181/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [182/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [183/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [184/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [185/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [186/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [187/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [188/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [189/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [190/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [191/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [192/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [193/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [194/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [195/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [196/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [197/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [198/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [199/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [200/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [201/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [202/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [203/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [204/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [205/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [206/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [207/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [208/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [209/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [210/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [211/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [212/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [213/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [214/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [215/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [216/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [217/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [218/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [219/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [220/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [221/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [222/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [223/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [224/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [225/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [226/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [227/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [228/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [229/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [230/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [231/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [232/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [233/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [234/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [235/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [236/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [237/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [238/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [239/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [240/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [241/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [242/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [243/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [244/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [245/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [246/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [247/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [248/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [249/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [250/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [251/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [252/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [253/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [254/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [255/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [256/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [257/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [258/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [259/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [260/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [261/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [262/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [263/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [264/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [265/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [266/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [267/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [268/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [269/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [270/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [271/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [272/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [273/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [274/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [275/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [276/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [277/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [278/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [279/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [280/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [281/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [282/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [283/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [284/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [285/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "\n",
      " [286/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [287/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [288/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [289/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [290/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [291/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [292/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [293/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [294/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [295/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [296/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [297/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [298/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [299/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [300/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [301/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [302/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [303/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [304/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [305/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [306/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [307/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [308/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [309/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [310/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [311/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [312/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [313/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [314/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [315/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [316/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [317/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [318/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [319/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [320/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [321/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [322/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [323/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [324/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [325/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [326/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [327/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [328/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [329/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [330/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [331/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [332/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [333/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [334/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [335/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [336/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [337/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [338/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [339/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [340/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [341/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [342/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [343/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [344/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [345/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [346/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [347/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [348/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [349/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [350/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [351/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [352/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [353/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [354/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [355/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [356/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [357/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [358/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [359/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [360/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [361/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [362/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [363/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [364/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [365/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [366/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [367/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [368/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [369/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [370/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [371/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [372/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [373/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [374/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [375/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [376/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [377/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [378/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [379/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [380/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [381/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [382/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [383/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [384/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [385/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [386/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [387/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [388/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [389/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [390/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [391/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [392/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [393/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [394/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [395/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [396/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [397/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [398/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [399/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [400/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [401/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [402/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [403/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [404/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [405/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [406/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [407/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [408/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [409/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [410/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [411/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [412/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [413/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [414/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [415/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [416/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [417/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [418/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [419/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [420/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [421/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [422/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [423/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [424/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [425/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [426/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [427/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [428/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [429/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "\n",
      " [430/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [431/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [432/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [433/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [434/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [435/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [436/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [437/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [438/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [439/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [440/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [441/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [442/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [443/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [444/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [445/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [446/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [447/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [448/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [449/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [450/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [451/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [452/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [453/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [454/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [455/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [456/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [457/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [458/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [459/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [460/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [461/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [462/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [463/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [464/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [465/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [466/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [467/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [468/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [469/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [470/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [471/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [472/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [473/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [474/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [475/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [476/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [477/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [478/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [479/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [480/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [481/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [482/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [483/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [484/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [485/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [486/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [487/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [488/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [489/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [490/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [491/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [492/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [493/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [494/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [495/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [496/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [497/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [498/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [499/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [500/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [501/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [502/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [503/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [504/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [505/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [506/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [507/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [508/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [509/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [510/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [511/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [512/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [513/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [514/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [515/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [516/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [517/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [518/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [519/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [520/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [521/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [522/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [523/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [524/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [525/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [526/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [527/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [528/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [529/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Decaimiento del learning rate: nuevo lr = 0.077378\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [530/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Decaimiento del learning rate: nuevo lr = 0.077378\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [531/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Decaimiento del learning rate: nuevo lr = 0.077378\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [532/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [533/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [534/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [535/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [536/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [537/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [538/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [539/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [540/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [541/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [542/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [543/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [544/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [545/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [546/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [547/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [548/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [549/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [550/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [551/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [552/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [553/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [554/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [555/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [556/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [557/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [558/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [559/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [560/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [561/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [562/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [563/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [564/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [565/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Decaimiento del learning rate: nuevo lr = 0.077378\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [566/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Decaimiento del learning rate: nuevo lr = 0.077378\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [567/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Decaimiento del learning rate: nuevo lr = 0.077378\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [568/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [569/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [570/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [571/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [572/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [573/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [574/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [575/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [576/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [1/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [2/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [3/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [4/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [5/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [6/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [7/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [8/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [9/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [10/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [11/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [12/192] lr=0.001, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [13/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [14/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [15/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [16/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [17/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [18/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [19/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [20/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [21/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [22/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [23/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [24/192] lr=0.001, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [25/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [26/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [27/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [28/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [29/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [30/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [31/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [32/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [33/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [34/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [35/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [36/192] lr=0.001, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [37/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [38/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [39/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [40/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [41/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [42/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [43/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [44/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [45/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [46/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [47/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [48/192] lr=0.001, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [49/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [50/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [51/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [52/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [53/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [54/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [55/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [56/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [57/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [58/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [59/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [60/192] lr=0.001, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [61/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [62/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [63/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [64/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [65/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [66/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [67/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [68/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [69/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [70/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [71/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [72/192] lr=0.001, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [73/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [74/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [75/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [76/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [77/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [78/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [79/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [80/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [81/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [82/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [83/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [84/192] lr=0.001, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [85/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [86/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [87/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [88/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [89/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [90/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [91/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [92/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [93/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [94/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [95/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [96/192] lr=0.001, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [97/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [98/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [99/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [100/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [101/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [102/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [103/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [104/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [105/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [106/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [107/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [108/192] lr=0.001, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [109/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [110/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [111/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [112/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [113/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [114/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [115/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [116/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [117/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [118/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [119/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [120/192] lr=0.001, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [121/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [122/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [123/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [124/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [125/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [126/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [127/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [128/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [129/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [130/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [131/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [132/192] lr=0.001, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [133/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [134/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [135/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [136/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [137/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [138/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [139/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [140/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [141/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [142/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [143/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [144/192] lr=0.001, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.000950\n",
      "Decaimiento del learning rate: nuevo lr = 0.000902\n",
      "Decaimiento del learning rate: nuevo lr = 0.000857\n",
      "Decaimiento del learning rate: nuevo lr = 0.000815\n",
      "Decaimiento del learning rate: nuevo lr = 0.000774\n",
      "Decaimiento del learning rate: nuevo lr = 0.000735\n",
      "Decaimiento del learning rate: nuevo lr = 0.000698\n",
      "Decaimiento del learning rate: nuevo lr = 0.000663\n",
      "Decaimiento del learning rate: nuevo lr = 0.000630\n",
      "Decaimiento del learning rate: nuevo lr = 0.000599\n",
      "\n",
      " [145/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [146/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [147/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [148/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [149/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [150/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [151/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [152/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [153/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [154/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [155/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [156/192] lr=0.005, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [157/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [158/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [159/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [160/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [161/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [162/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [163/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [164/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [165/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [166/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [167/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [168/192] lr=0.005, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [169/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [170/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [171/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [172/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [173/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [174/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [175/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [176/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [177/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [178/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [179/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [180/192] lr=0.005, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [181/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [182/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [183/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [184/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [185/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [186/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [187/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [188/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [189/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [190/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [191/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [192/192] lr=0.005, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [193/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [194/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [195/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [196/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [197/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [198/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [199/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [200/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [201/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [202/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [203/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [204/192] lr=0.005, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [205/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [206/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [207/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [208/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [209/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [210/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [211/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [212/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [213/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [214/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [215/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [216/192] lr=0.005, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [217/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [218/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [219/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [220/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [221/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [222/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [223/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [224/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [225/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [226/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [227/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [228/192] lr=0.005, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [229/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [230/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [231/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [232/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [233/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [234/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [235/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [236/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [237/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [238/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [239/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [240/192] lr=0.005, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [241/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [242/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [243/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [244/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [245/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [246/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [247/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [248/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [249/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [250/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [251/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [252/192] lr=0.005, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [253/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [254/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [255/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [256/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [257/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [258/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [259/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [260/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [261/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [262/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [263/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [264/192] lr=0.005, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [265/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [266/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [267/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [268/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [269/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [270/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [271/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [272/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [273/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [274/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [275/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [276/192] lr=0.005, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [277/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [278/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [279/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [280/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [281/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [282/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [283/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [284/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [285/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Decaimiento del learning rate: nuevo lr = 0.004513\n",
      "Decaimiento del learning rate: nuevo lr = 0.004287\n",
      "Decaimiento del learning rate: nuevo lr = 0.004073\n",
      "Decaimiento del learning rate: nuevo lr = 0.003869\n",
      "Decaimiento del learning rate: nuevo lr = 0.003675\n",
      "Decaimiento del learning rate: nuevo lr = 0.003492\n",
      "Decaimiento del learning rate: nuevo lr = 0.003317\n",
      "Decaimiento del learning rate: nuevo lr = 0.003151\n",
      "Decaimiento del learning rate: nuevo lr = 0.002994\n",
      "\n",
      " [286/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [287/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [288/192] lr=0.005, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.004750\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [289/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [290/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [291/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [292/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [293/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [294/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [295/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [296/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [297/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [298/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [299/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [300/192] lr=0.01, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [301/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [302/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [303/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [304/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [305/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [306/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [307/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [308/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [309/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [310/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [311/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [312/192] lr=0.01, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [313/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [314/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [315/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [316/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [317/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [318/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [319/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [320/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [321/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [322/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [323/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [324/192] lr=0.01, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [325/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [326/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [327/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [328/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [329/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [330/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [331/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [332/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [333/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [334/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [335/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [336/192] lr=0.01, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [337/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [338/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [339/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [340/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [341/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [342/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [343/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [344/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [345/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [346/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [347/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [348/192] lr=0.01, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [349/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [350/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [351/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [352/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [353/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [354/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [355/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [356/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [357/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [358/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [359/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [360/192] lr=0.01, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [361/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [362/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [363/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [364/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [365/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [366/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [367/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [368/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [369/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [370/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [371/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [372/192] lr=0.01, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [373/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [374/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [375/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [376/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [377/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [378/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [379/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [380/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [381/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [382/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [383/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [384/192] lr=0.01, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [385/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [386/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [387/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [388/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [389/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [390/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [391/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [392/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [393/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [394/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [395/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [396/192] lr=0.01, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [397/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [398/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [399/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [400/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [401/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [402/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [403/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [404/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [405/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [406/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [407/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [408/192] lr=0.01, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [409/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [410/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [411/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [412/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [413/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [414/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [415/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [416/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [417/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [418/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [419/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [420/192] lr=0.01, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [421/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [422/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [423/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [424/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [425/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [426/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [427/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [428/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [429/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.009500\n",
      "Decaimiento del learning rate: nuevo lr = 0.009025\n",
      "Decaimiento del learning rate: nuevo lr = 0.008574\n",
      "Decaimiento del learning rate: nuevo lr = 0.008145\n",
      "Decaimiento del learning rate: nuevo lr = 0.007738\n",
      "Decaimiento del learning rate: nuevo lr = 0.007351\n",
      "Decaimiento del learning rate: nuevo lr = 0.006983\n",
      "Decaimiento del learning rate: nuevo lr = 0.006634\n",
      "Decaimiento del learning rate: nuevo lr = 0.006302\n",
      "Decaimiento del learning rate: nuevo lr = 0.005987\n",
      "\n",
      " [430/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [431/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [432/192] lr=0.01, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [433/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [434/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [435/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [436/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [437/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [438/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [439/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [440/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [441/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [442/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [443/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [444/192] lr=0.1, batch=16, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [445/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [446/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [447/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [448/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [449/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [450/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [451/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [452/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [453/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [454/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [455/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [456/192] lr=0.1, batch=16, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [457/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [458/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [459/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [460/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [461/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [462/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [463/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [464/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [465/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [466/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [467/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [468/192] lr=0.1, batch=16, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [469/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [470/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [471/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [472/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [473/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [474/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [475/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [476/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [477/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [478/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [479/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [480/192] lr=0.1, batch=16, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [481/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [482/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [483/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [484/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [485/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [486/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [487/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [488/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [489/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [490/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [491/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [492/192] lr=0.1, batch=16, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [493/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [494/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [495/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [496/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [497/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [498/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [499/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [500/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [501/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [502/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [503/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [504/192] lr=0.1, batch=16, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [505/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [506/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [507/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [508/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [509/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [510/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [511/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [512/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [513/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [514/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [515/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [516/192] lr=0.1, batch=32, λ=0.0001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [517/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [518/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [519/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [520/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [521/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [522/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [523/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [524/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [525/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [526/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [527/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [528/192] lr=0.1, batch=32, λ=0.0001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [529/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Decaimiento del learning rate: nuevo lr = 0.077378\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [530/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Decaimiento del learning rate: nuevo lr = 0.077378\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [531/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Decaimiento del learning rate: nuevo lr = 0.077378\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [532/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [533/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [534/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [535/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [536/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [537/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [538/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [539/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [540/192] lr=0.1, batch=32, λ=0.0001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [541/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [542/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [543/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [544/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [545/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [546/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [547/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [548/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [549/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [550/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [551/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [552/192] lr=0.1, batch=32, λ=0.001, layers=[8], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [553/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [554/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [555/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [556/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [557/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [558/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [559/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [560/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [561/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [562/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [563/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [564/192] lr=0.1, batch=32, λ=0.001, layers=[12], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [565/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Decaimiento del learning rate: nuevo lr = 0.077378\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [566/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Decaimiento del learning rate: nuevo lr = 0.077378\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [567/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=relu, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Decaimiento del learning rate: nuevo lr = 0.077378\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [568/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [569/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [570/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=relu, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [571/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [572/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [573/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.9,0.999)\n",
      "Decaimiento del learning rate: nuevo lr = 0.095000\n",
      "Decaimiento del learning rate: nuevo lr = 0.090250\n",
      "Decaimiento del learning rate: nuevo lr = 0.085737\n",
      "Decaimiento del learning rate: nuevo lr = 0.081451\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [574/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [575/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n",
      "\n",
      " [576/192] lr=0.1, batch=32, λ=0.001, layers=[6], act=tanh, β=(0.99,0.95)\n",
      "Early stopping: sin mejora tras 10 épocas.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lambda_reg</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>activation</th>\n",
       "      <th>beta1</th>\n",
       "      <th>beta2</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>best_val_acc</th>\n",
       "      <th>best_val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>484</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[12]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id   lr  batch_size  lambda_reg hidden_layers activation  beta1  beta2  \\\n",
       "0  484  0.1          16       0.001          [12]       relu   0.99   0.95   \n",
       "\n",
       "   dropout_rate  best_val_acc  best_val_loss  \n",
       "0           0.0           1.0       0.000031  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner = HyperparameterTuner(X_train, Y_train, X_val, Y_val)\n",
    "for e in [100, 150, 200]:\n",
    "    results = tuner.search(\n",
    "        lr_list=[0.001, 0.005, 0.01, 0.1],\n",
    "        batch_sizes=[16, 32],\n",
    "        regs=[0.0001, 0.001],\n",
    "        hidden_layers=[[8], [12], [6]],\n",
    "        activations=[\"relu\", \"tanh\"],\n",
    "        betas=[(0.9, 0.999), (0.99, 0.95)],\n",
    "        dropout_rates=[0.0, 0.2, 0.5],\n",
    "        epochs=e,\n",
    "        patience=10,\n",
    "        decay=0.95,\n",
    "        seed=42\n",
    "    )\n",
    "df_results = pd.DataFrame(results)\n",
    "best = df_results.sort_values(by=[\"best_val_acc\", \"best_val_loss\"], ascending=[False, True]).head(5)\n",
    "best.iloc[[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb9ddc5",
   "metadata": {},
   "source": [
    "#### 4. Modelo, optimizador y entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb6bf2b",
   "metadata": {},
   "source": [
    "A partir del grid (o fijando manualmente), definimos:\n",
    "- Arquitectura MLP [4, 12, 3]: 4 entradas (mediciones), una capa oculta de 12 neuronas y 3 salidas (clases).\n",
    "- Activación ReLU, salida softmax, pérdida CCE, inicialización Xavier, L2 y dropout (aquí desactivado).\n",
    "- Adam con hiperparámetros seleccionados y decaimiento del learning rate en el Trainer.\n",
    "- Entrenamiento con mini-lotes y registro de historial (hist[\"train_loss\"], hist[\"val_loss\"], hist[\"train_acc\"], hist[\"val_acc\"]).\n",
    "\n",
    "El criterio de parada es el early stopping con paciencia 10. Se conserva el mejor checkpoint por validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a365a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 001 | Train Loss: 3.6995 | Train Acc: 68.75% | Val Loss: 4.5504 | Val Acc: 73.33%\n",
      "Época 002 | Train Loss: 3.0839 | Train Acc: 80.47% | Val Loss: 2.7704 | Val Acc: 73.33%\n",
      "Época 003 | Train Loss: 3.3292 | Train Acc: 67.19% | Val Loss: 4.0750 | Val Acc: 53.33%\n",
      "Época 004 | Train Loss: 1.9237 | Train Acc: 75.78% | Val Loss: 2.0156 | Val Acc: 73.33%\n",
      "Época 005 | Train Loss: 2.1335 | Train Acc: 78.12% | Val Loss: 1.3663 | Val Acc: 80.00%\n",
      "Época 006 | Train Loss: 1.9139 | Train Acc: 78.91% | Val Loss: 0.1214 | Val Acc: 86.67%\n",
      "Época 007 | Train Loss: 1.7231 | Train Acc: 79.69% | Val Loss: 0.0480 | Val Acc: 100.00%\n",
      "Época 008 | Train Loss: 1.2458 | Train Acc: 86.72% | Val Loss: 0.0131 | Val Acc: 100.00%\n",
      "Época 009 | Train Loss: 0.7779 | Train Acc: 86.72% | Val Loss: 0.0038 | Val Acc: 100.00%\n",
      "Época 010 | Train Loss: 0.5325 | Train Acc: 87.50% | Val Loss: 0.0017 | Val Acc: 100.00%\n",
      "Época 011 | Train Loss: 0.3403 | Train Acc: 92.97% | Val Loss: 0.1372 | Val Acc: 93.33%\n",
      "Época 012 | Train Loss: 0.3502 | Train Acc: 90.62% | Val Loss: 0.0727 | Val Acc: 93.33%\n",
      "Época 013 | Train Loss: 0.5280 | Train Acc: 90.62% | Val Loss: 0.0008 | Val Acc: 100.00%\n",
      "Época 014 | Train Loss: 0.3383 | Train Acc: 93.75% | Val Loss: 0.0004 | Val Acc: 100.00%\n",
      "Época 015 | Train Loss: 0.2233 | Train Acc: 94.53% | Val Loss: 0.0006 | Val Acc: 100.00%\n",
      "Época 016 | Train Loss: 0.2459 | Train Acc: 93.75% | Val Loss: 0.0007 | Val Acc: 100.00%\n",
      "Época 017 | Train Loss: 0.2023 | Train Acc: 95.31% | Val Loss: 0.7965 | Val Acc: 93.33%\n",
      "Época 018 | Train Loss: 0.1497 | Train Acc: 95.31% | Val Loss: 1.2282 | Val Acc: 93.33%\n",
      "Época 019 | Train Loss: 0.1207 | Train Acc: 94.53% | Val Loss: 1.2281 | Val Acc: 93.33%\n",
      "Decaimiento del learning rate: nuevo lr = 0.090000\n",
      "Época 020 | Train Loss: 0.1419 | Train Acc: 93.75% | Val Loss: 0.9226 | Val Acc: 93.33%\n",
      "Época 021 | Train Loss: 0.1563 | Train Acc: 94.53% | Val Loss: 0.0001 | Val Acc: 100.00%\n",
      "Época 022 | Train Loss: 0.1240 | Train Acc: 94.53% | Val Loss: 0.0001 | Val Acc: 100.00%\n",
      "Época 023 | Train Loss: 0.0810 | Train Acc: 96.88% | Val Loss: 0.0001 | Val Acc: 100.00%\n",
      "Época 024 | Train Loss: 0.1009 | Train Acc: 95.31% | Val Loss: 0.0002 | Val Acc: 100.00%\n",
      "Época 025 | Train Loss: 0.1269 | Train Acc: 96.09% | Val Loss: 0.0810 | Val Acc: 93.33%\n",
      "Época 026 | Train Loss: 0.1268 | Train Acc: 96.09% | Val Loss: 0.1604 | Val Acc: 93.33%\n",
      "Época 027 | Train Loss: 0.1000 | Train Acc: 95.31% | Val Loss: 0.0002 | Val Acc: 100.00%\n",
      "Época 028 | Train Loss: 0.0616 | Train Acc: 96.88% | Val Loss: 0.0001 | Val Acc: 100.00%\n",
      "Época 029 | Train Loss: 0.0556 | Train Acc: 97.66% | Val Loss: 0.0000 | Val Acc: 100.00%\n",
      "Época 030 | Train Loss: 0.0955 | Train Acc: 95.31% | Val Loss: 0.0000 | Val Acc: 100.00%\n",
      "Época 031 | Train Loss: 0.0991 | Train Acc: 96.09% | Val Loss: 0.0011 | Val Acc: 100.00%\n",
      "Época 032 | Train Loss: 0.0787 | Train Acc: 96.09% | Val Loss: 0.0001 | Val Acc: 100.00%\n",
      "Época 033 | Train Loss: 0.0585 | Train Acc: 97.66% | Val Loss: 0.0010 | Val Acc: 100.00%\n",
      "Época 034 | Train Loss: 0.0729 | Train Acc: 96.88% | Val Loss: 0.0181 | Val Acc: 100.00%\n",
      "Época 035 | Train Loss: 0.1305 | Train Acc: 94.53% | Val Loss: 0.0153 | Val Acc: 100.00%\n",
      "Época 036 | Train Loss: 0.1452 | Train Acc: 95.31% | Val Loss: 0.0290 | Val Acc: 100.00%\n",
      "Época 037 | Train Loss: 0.0852 | Train Acc: 95.31% | Val Loss: 0.0655 | Val Acc: 93.33%\n",
      "Época 038 | Train Loss: 0.1959 | Train Acc: 95.31% | Val Loss: 0.1503 | Val Acc: 93.33%\n",
      "Época 039 | Train Loss: 0.1487 | Train Acc: 96.09% | Val Loss: 0.1826 | Val Acc: 93.33%\n",
      "Early stopping: sin mejora tras 10 épocas.\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(layers=[4, 12, 3], activation='relu', output_activation='softmax', loss='cce', seed=42, init='xavier', lambda_reg=0.001, dropout_rate=0.0)\n",
    "optimizer = OptimizerAdam(lr=0.1, beta1=0.99, beta2=0.95, eps=1e-8)\n",
    "trainer = Trainer(model, optimizer, categorical_cross_entropy, patience=10, decay=0.9)\n",
    "\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "accuracy_train = []\n",
    "accuracy_val = []\n",
    "\n",
    "hist = trainer.train(X_train, Y_train, X_val, Y_val, epochs=180, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd4d407",
   "metadata": {},
   "source": [
    "#### 5. Evaluación y visualización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da63dd35",
   "metadata": {},
   "source": [
    "En primer lugar, inferimos sobre el conjunto de prueba y calculamos accuracy. En sehundo lugar, dibujamos la evolución de la pérdida y de la precisión (train/val) por época para analizar convergencia y posibles brechas. Finalmente, mostramos una matriz de confusión simple para localizar errores por clase (típicamente, confusiones entre versicolor y virginica)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "349d4bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión final en test: 93.33%\n"
     ]
    }
   ],
   "source": [
    "A_pred, _ = model.forward(X_test)\n",
    "y_pred = np.argmax(A_pred.T, axis=1)\n",
    "y_true = np.argmax(Y_test, axis=1)\n",
    "accuracy_test = np.mean(y_pred == y_true)\n",
    "print(f\"Precisión final en test: {accuracy_test*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339fb374",
   "metadata": {},
   "source": [
    "5.1 Gráfica evolución de las pérdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8e78a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(hist[\"train_loss\"], label=\"Train Loss\", color='blue')\n",
    "plt.plot(hist[\"val_loss\"], label=\"Val Loss\", color='orange')\n",
    "plt.title(\"Evolución de la función de pérdida\")\n",
    "plt.xlabel(\"Épocas\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5c51e7",
   "metadata": {},
   "source": [
    "5.2 Gráfica de la evolución de la precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da14fee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(hist[\"train_acc\"], label=\"Train Acc\", color='green')\n",
    "plt.plot(hist[\"val_acc\"], label=\"Val Acc\", color='red')\n",
    "plt.title(\"Evolución de la precisión\")\n",
    "plt.xlabel(\"Épocas\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5700a00a",
   "metadata": {},
   "source": [
    "5.3 Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a67bd92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "   Predicciones →\n",
      "Reales ↓\n",
      "       0 |    2    0    0\n",
      "       1 |    0    6    0\n",
      "       2 |    0    1    6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0],\n",
       "       [0, 6, 0],\n",
       "       [0, 1, 6]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def confusion_matrix_simple(y_true, y_pred, labels=None):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    if labels is None:\n",
    "        labels = np.unique(np.concatenate((y_true, y_pred)))\n",
    "    n = len(labels)\n",
    "    matrix = np.zeros((n, n), dtype=int)\n",
    "    for i, true_label in enumerate(labels):\n",
    "        for j, pred_label in enumerate(labels):\n",
    "            matrix[i, j] = np.sum((y_true == true_label) & (y_pred == pred_label))\n",
    "    print(\"Matriz de confusión:\")\n",
    "    print(\"   Predicciones →\")\n",
    "    print(\"Reales ↓\")\n",
    "    for i, true_label in enumerate(labels):\n",
    "        print(f\"{true_label:>8} |\", \" \".join(f\"{x:4d}\" for x in matrix[i]))\n",
    "    return matrix\n",
    "\n",
    "confusion_matrix_simple(y_true, y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
